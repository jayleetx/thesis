# Methods and Structure {#methods}

Inevitably, the data format that would be ideal to conduct this research doesn't exist publicly (as it shouldn't - voter anonymity and such). The ideal model might be a logistic or other classification model that predicts whether a given voter has a ballot error or fills out the ballot incompletely, given their demographic qualities.

### Data Structure and Source

The data used comes from two main sources. From the San Francisco Elections Office <!-- Get an official title? -->, we have a cast ballot record of the election in question <!-- Put a date on this! -->. This is presented by the city as two text files:
- The ballot image, a 45-character fixed-width file with fields corresponding to election, candidate, unique voter number (anonymized and disconnected from any voter registration ID), ranking, precinct, and other information. Each of these is encoded numerically, so each line of the file appears as a 45-digit number.
- The lookup table, an 83-character fixed-width file that defines the encodings used to create the numerical values in the ballot image.
<!-- Get the pictures that explain these! -->

In the ballot file, each voter is spread across three rows of data (one for each ranking). We use the `clean_ballot()` function from our `rcv` R package <!-- cite this somehow? idk --> to read in the data for easier manipulation. From this data we have the full ranked preference set of candidates (up to 3) from each voter.

Since the voter-level data is fully anonymized, we have no demographic information at the individual level. For any given voter, since the most identifying piece of information we have about them is their precinct, it is impossible to know any one voter's gender or ethnicity. To gain insight into these demographic trends, we instead aggregate up to the precinct level.

At the precinct level, we can now only study the rates of these ballot phenomena. For example, in Precinct 1703, we may see 14% of voters undervote. <!-- Get a real stat to use for this --> Rather than building a classification model (error / no error), we can now instead build regression models with a numerical dependent variable <!-- Better word for this --> - the rate of ballot error. Moving up this level of abstraction does remove some granularity from the model (inference and prediction at the precinct level is less specific than at the individual level), but this is the least we can do and still be able to access demographic information.
<!-- Talk about the actual processes (and files) used to do this -->

Now that we have precinct-level rates, we need to obtain precinct-level demographic information in order to build a model. Our source of demographic data is the 2010 U.S. Census (citation). While this data is slightly out of date (about 8 years), there is more certainty about the accuracy of the measurements collected. While a more temporally accurate data set like the yearly American Community Survey (ACS) could have been used, the error margins of this data set proved too large / complicated to be useful for this study.

One consideration with this is that the voting population is not always representative of the general population. It might be more informative to obtain demographics about the voting population specifically, rather than the entire population of each precinct. <!-- Find out how many people in each precinct voted. Should be some easy math once you find the population of the precincts. --> However, the only information available about voters is their age (from the county voter registration file), and the discontinuity introduced by using two different data sets for demographic information is more of an  "error" to me than using a less accurate (but universal) census data set.

We now encounter a problem. Since census regions (block groups, tracts) are set by the federal government, and election precincts are set by San Francisco County^[The city and county government are unified in this case, because the county comprises entirely of the city of San Francisco.], the regions don't line up nicely^[There's no inherent reason that they should, it's just unfortunate for this study.]. <!-- show a picture of this! You have two maps --> Given this mismatch, how do we obtain demographic estimates for our precincts?

Stated more generally: if we have a division of a geographic region and some non-constant properties^[A constant property is something that is identical across all of its points: if a precinct is inside State House District 4, any point or region inside of it is inside State House District 4. A non-constant property is not identical across its interior: if there are 100 people in a precinct, there are not 100 people inside any arbitrary sub-region of the district.] on the divisions, how do we estimate measures of these properties for other possible divisions?
<!-- Is there research into this? What's up? -->
There are a few possible ways of accomplishing this. The way we use assumes a uniform spatial distribution of all non-constant properties: any sub-region has proportion of the full region's property equal to the proportion of the area of the full region that the sub-region occupies. For example, if we split a region with 100 people into two sub-regions of equal area, we assume that there are 50 people in each sub-region.
<!-- add a pic of the validation data because it's easier to comprehend -->
To approach this method, we first spatially intersect the two division sets of the city: census tracts and election precincts. This creates a new division, where every new sub-region is a unique combination of tract and precinct <!-- This might not be true? What if there's a weird concave shape that gets split up? --> We can directly group these sub-regions together in one combination into the full set of precincts, and group them in another combination into the full set of census tracts. Using the uniform spatial assumption, we obtain demographic estimates for each of these sub-regions, then add them together in the precinct grouping to obtain demographic estimates for our precincts.

<!-- Add general example with the test data here, it's way easier to understand. -->

This assumption of uniformity, like any assumption, may be unfounded. There are methods, some involving satellite imagery, to get more accurate information about population distribution. Quite honestly, these were just too complicated for the scope of this research. It is, however, more likely in an urban environment like San Francisco^[as compared to the entire state of California, which has urban pockets within suburban regions within a rural overall condition] that this unifrmity assumption will not drastically change our estimates.

